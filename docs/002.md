# 002 - From-Scratch Project Setup Guide (with Full Source)

This guide walks you through creating the entire project from an empty folder on WSL/Linux, including required Azure setup, environment configuration, installation, and running the API. It also embeds the full source code of each essential file for easy bootstrap.

## 1) Prerequisites
- Python 3.10+ on WSL/Ubuntu
- Azure CLI logged in and subscription selected
- Cosmos DB account, database, and container; Storage account created

## 2) Create and Initialize the Repo
```bash
# Create project folder
mkdir mseone_poc && cd mseone_poc

# Create and activate venv (optional)
python3 -m venv .venv
source .venv/bin/activate

# Basic structure
mkdir -p app/{models,services,resolvers,middleware,schema} config docs tests azure scripts monitoring
printf "" > config/__init__.py
printf "" > tests/__init__.py
```

## 3) Create Files (copy-paste contents below)

### requirements.txt
```txt
# Core FastAPI and GraphQL dependencies
fastapi==0.104.1
uvicorn[standard]==0.24.0
strawberry-graphql[fastapi]==0.217.0

# Azure SDK dependencies
azure-cosmos==4.5.1
azure-storage-blob==12.19.0
azure-identity==1.15.0

# Configuration and validation
pydantic==2.5.0
pydantic-settings==2.1.0
python-dotenv==1.0.0

# HTTP client
httpx==0.25.2

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0

# Code quality
black==23.11.0
isort==5.12.0
flake8==6.1.0

# Development
python-multipart==0.0.6
```

### config/settings.py
```python
"""
Configuration settings for DevOps PoC
Manages Azure service connections and API settings
"""
from pydantic_settings import BaseSettings
from functools import lru_cache
import os

class Settings(BaseSettings):
    # API Configuration
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 8000
    DEBUG: bool = True
    LOG_LEVEL: str = "INFO"
    
    # Azure Configuration (PoC Requirements)
    AZURE_TENANT_ID: str
    AZURE_CLIENT_ID: str
    AZURE_CLIENT_SECRET: str
    AZURE_SUBSCRIPTION_ID: str
    
    # Azure AD Authentication (PoC Requirement)
    AZURE_AD_AUTHORITY: str
    AZURE_AD_AUDIENCE: str
    
    # CosmosDB Configuration (PoC Requirement)
    COSMOS_DB_URI: str
    COSMOS_DB_KEY: str
    COSMOS_DB_DATABASE: str = "devops-poc"
    COSMOS_DB_CONTAINER: str = "projects"
    
    # Azure Storage Configuration (PoC Requirement)
    STORAGE_ACCOUNT_NAME: str
    STORAGE_CONNECTION_STRING: str
    STORAGE_CONTAINER_NAME: str = "api-results"
    
    # Logic Apps Configuration (PoC Requirement)
    LOGIC_APP_TRIGGER_URL: str = ""
    TEAMS_WEBHOOK_URL: str = ""
    
    class Config:
        env_file = ".env"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()

# Validate required Azure settings
def validate_azure_config():
    """Validate that all required Azure configurations are present"""
    settings = get_settings()
    required_fields = [
        "AZURE_TENANT_ID",
        "AZURE_CLIENT_ID", 
        "COSMOS_DB_URI",
        "STORAGE_ACCOUNT_NAME"
    ]
    
    missing_fields = []
    for field in required_fields:
        if not getattr(settings, field, None):
            missing_fields.append(field)
    
    if missing_fields:
        raise ValueError(f"Missing required Azure configuration: {missing_fields}")
    
    return True
```

### app/models/project.py
```python
"""
Project model for DevOps PoC
Defines the data structure for project metadata and GraphQL schema
"""
from typing import Optional, List
from datetime import datetime
from pydantic import BaseModel, Field
import strawberry
from strawberry.scalars import ID


@strawberry.type
class ProjectStats:
    """Project statistics for GraphQL schema"""
    total_projects: int
    status_distribution: str
    priority_distribution: str
    team_distribution: str
    last_updated: str

@strawberry.type
class Project:
    """Project entity for GraphQL schema"""
    id: ID
    name: str
    description: str
    status: str
    owner: str
    team: str
    created_at: datetime
    updated_at: datetime
    tags: List[str]
    priority: str
    estimated_completion: Optional[datetime] = None
    actual_completion: Optional[datetime] = None
    budget: Optional[float] = None
    risk_level: str = "LOW"
    dependencies: List[str] = Field(default_factory=list)


class ProjectCreate(BaseModel):
    """Input model for creating projects"""
    name: str = Field(..., min_length=1, max_length=100)
    description: str = Field(..., min_length=1, max_length=500)
    status: str = Field(default="PLANNING", pattern="^(PLANNING|IN_PROGRESS|COMPLETED|ON_HOLD|CANCELLED)$")
    owner: str = Field(..., min_length=1)
    team: str = Field(..., min_length=1)
    tags: List[str] = Field(default_factory=list)
    priority: str = Field(default="MEDIUM", pattern="^(LOW|MEDIUM|HIGH|CRITICAL)$")
    estimated_completion: Optional[datetime] = None
    budget: Optional[float] = Field(None, ge=0)
    risk_level: str = Field(default="LOW", pattern="^(LOW|MEDIUM|HIGH|CRITICAL)$")
    dependencies: List[str] = Field(default_factory=list)


class ProjectUpdate(BaseModel):
    """Input model for updating projects"""
    name: Optional[str] = Field(None, min_length=1, max_length=100)
    description: Optional[str] = Field(None, min_length=1, max_length=500)
    status: Optional[str] = Field(None, pattern="^(PLANNING|IN_PROGRESS|COMPLETED|ON_HOLD|CANCELLED)$")
    owner: Optional[str] = Field(None, min_length=1)
    team: Optional[str] = Field(None, min_length=1)
    tags: Optional[List[str]] = None
    priority: Optional[str] = Field(None, pattern="^(LOW|MEDIUM|HIGH|CRITICAL)$")
    estimated_completion: Optional[datetime] = None
    actual_completion: Optional[datetime] = None
    budget: Optional[float] = Field(None, ge=0)
    risk_level: Optional[str] = Field(None, pattern="^(LOW|MEDIUM|HIGH|CRITICAL)$")
    dependencies: Optional[List[str]] = None


class ProjectFilter(BaseModel):
    """Filter model for project queries"""
    status: Optional[str] = None
    owner: Optional[str] = None
    team: Optional[str] = None
    priority: Optional[str] = None
    risk_level: Optional[str] = None
    tags: Optional[List[str]] = None
    created_after: Optional[datetime] = None
    created_before: Optional[datetime] = None


class ProjectPagination(BaseModel):
    """Pagination model for project queries"""
    limit: int = Field(default=10, ge=1, le=100)
    offset: int = Field(default=0, ge=0)
    sort_by: str = Field(default="created_at")
    sort_order: str = Field(default="desc", pattern="^(asc|desc)$")


# Strawberry input types
@strawberry.input
class ProjectCreateInput:
    name: str
    description: str
    status: str = "PLANNING"
    owner: str
    team: str
    tags: List[str] = Field(default_factory=list)
    priority: str = "MEDIUM"
    estimated_completion: Optional[datetime] = None
    budget: Optional[float] = None
    risk_level: str = "LOW"
    dependencies: List[str] = Field(default_factory=list)


@strawberry.input
class ProjectUpdateInput:
    name: Optional[str] = None
    description: Optional[str] = None
    status: Optional[str] = None
    owner: Optional[str] = None
    team: Optional[str] = None
    tags: Optional[List[str]] = None
    priority: Optional[str] = None
    estimated_completion: Optional[datetime] = None
    actual_completion: Optional[datetime] = None
    budget: Optional[float] = None
    risk_level: Optional[str] = None
    dependencies: Optional[List[str]] = None


@strawberry.input
class ProjectFilterInput:
    status: Optional[str] = None
    owner: Optional[str] = None
    team: Optional[str] = None
    priority: Optional[str] = None
    risk_level: Optional[str] = None
    tags: Optional[List[str]] = None
    created_after: Optional[datetime] = None
    created_before: Optional[datetime] = None


@strawberry.input
class ProjectPaginationInput:
    limit: int = 10
    offset: int = 0
    sort_by: str = "created_at"
    sort_order: str = "desc"
```

### app/services/cosmos_db.py
```python
"""
Cosmos DB Service for DevOps PoC
Implements real Cosmos DB operations for project management
"""
from typing import Any, Dict, List, Optional
import json
import logging
from datetime import datetime
from azure.cosmos import CosmosClient, PartitionKey
from azure.cosmos.exceptions import CosmosHttpResponseError

from config.settings import get_settings

logger = logging.getLogger(__name__)


class CosmosDBService:
    """Real Cosmos DB service implementation"""
    
    def __init__(self):
        """Initialize Cosmos DB client"""
        settings = get_settings()
        
        self.client = CosmosClient(
            url=settings.COSMOS_DB_URI,
            credential=settings.COSMOS_DB_KEY
        )
        
        self.database_name = settings.COSMOS_DB_DATABASE
        self.container_name = settings.COSMOS_DB_CONTAINER
        
        # Get database and container references
        self.database = self.client.get_database_client(self.database_name)
        self.container = self.database.get_container_client(self.container_name)
        
        logger.info(f"Cosmos DB service initialized for database: {self.database_name}")
    
    async def test_connection(self) -> bool:
        """Test Cosmos DB connectivity"""
        try:
            # Try to read container properties
            properties = self.container.read()
            logger.info(f"✅ Cosmos DB connection successful. Container: {properties['id']}")
            return True
        except CosmosHttpResponseError as e:
            logger.error(f"❌ Cosmos DB connection failed: {e}")
            return False
        except Exception as e:
            logger.error(f"❌ Unexpected error testing Cosmos DB: {e}")
            return False
    
    async def get_project(self, project_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve a project by ID"""
        try:
            response = self.container.read_item(
                item=project_id,
                partition_key=project_id
            )
            logger.info(f"Retrieved project: {project_id}")
            return response
        except CosmosHttpResponseError as e:
            if e.status_code == 404:
                logger.info(f"Project not found: {project_id}")
                return None
            logger.error(f"Error retrieving project {project_id}: {e}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error retrieving project {project_id}: {e}")
            return None
    
    async def list_projects(
        self, 
        filter_params: Optional[Dict[str, Any]] = None,
        pagination_params: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """List projects with optional filtering and pagination"""
        try:
            # Build query
            query = "SELECT * FROM c"
            parameters = []
            
            # Add filters
            if filter_params:
                conditions = []
                param_count = 0
                
                for key, value in filter_params.items():
                    if value is not None:
                        if key == "tags" and isinstance(value, list):
                            # Handle array contains for tags
                            tag_conditions = []
                            for tag in value:
                                param_count += 1
                                param_name = f"@tag{param_count}"
                                tag_conditions.append(f"ARRAY_CONTAINS(c.{key}, {param_name})")
                                parameters.append({"name": param_name, "value": tag})
                            if tag_conditions:
                                conditions.append(f"({' AND '.join(tag_conditions)})")
                        elif key in ["created_after", "created_before"]:
                            # Handle date comparisons
                            param_count += 1
                            param_name = f"@{key}{param_count}"
                            if key == "created_after":
                                conditions.append(f"c.created_at >= {param_name}")
                            else:
                                conditions.append(f"c.created_at <= {param_name}")
                            parameters.append({"name": param_name, "value": value.isoformat()})
                        else:
                            # Handle simple equality
                            param_count += 1
                            param_name = f"@{key}{param_count}"
                            conditions.append(f"c.{key} = {param_name}")
                            parameters.append({"name": param_name, "value": value})
                
                if conditions:
                    query += " WHERE " + " AND ".join(conditions)
            
            # Add sorting
            if pagination_params and pagination_params.get("sort_by"):
                sort_field = pagination_params["sort_by"]
                sort_order = pagination_params.get("sort_order", "desc").upper()
                query += f" ORDER BY c.{sort_field} {sort_order}"
            
            # Execute query
            items = list(self.container.query_items(
                query=query,
                parameters=parameters,
                enable_cross_partition_query=True
            ))
            
            # Apply pagination
            if pagination_params:
                offset = pagination_params.get("offset", 0)
                limit = pagination_params.get("limit", 10)
                items = items[offset:offset + limit]
            
            logger.info(f"Retrieved {len(items)} projects")
            return items
            
        except Exception as e:
            logger.error(f"Error listing projects: {e}")
            return []
    
    async def create_project(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new project"""
        try:
            # Ensure required fields
            if "id" not in project_data:
                raise ValueError("Project ID is required")
            
            # Add metadata
            project_data["_ts"] = int(datetime.utcnow().timestamp())
            project_data["_etag"] = None
            
            # Create the item
            response = self.container.create_item(
                body=project_data,
                partition_key=project_data["id"]
            )
            
            logger.info(f"Created project: {project_data['id']}")
            return response
            
        except Exception as e:
            logger.error(f"Error creating project: {e}")
            raise
    
    async def update_project(self, project_id: str, updates: Dict[str, Any]) -> Dict[str, Any]:
        """Update an existing project"""
        try:
            # Get existing project
            existing_project = await self.get_project(project_id)
            if not existing_project:
                raise ValueError(f"Project {project_id} not found")
            
            # Apply updates
            updated_project = {**existing_project, **updates}
            updated_project["_ts"] = int(datetime.utcnow().timestamp())
            
            # Update the item
            response = self.container.replace_item(
                item=project_id,
                body=updated_project,
                partition_key=project_id
            )
            
            logger.info(f"Updated project: {project_id}")
            return response
            
        except Exception as e:
            logger.error(f"Error updating project {project_id}: {e}")
            raise
    
    async def delete_project(self, project_id: str) -> bool:
        """Delete a project"""
        try:
            self.container.delete_item(
                item=project_id,
                partition_key=project_id
            )
            
            logger.info(f"Deleted project: {project_id}")
            return True
            
        except CosmosHttpResponseError as e:
            if e.status_code == 404:
                logger.info(f"Project not found for deletion: {project_id}")
                return False
            logger.error(f"Error deleting project {project_id}: {e}")
            return False
        except Exception as e:
            logger.error(f"Unexpected error deleting project {project_id}: {e}")
            return False
    
    async def get_project_stats(self) -> Dict[str, Any]:
        """Get project statistics"""
        try:
            # Count total projects
            total_query = "SELECT VALUE COUNT(1) FROM c"
            total_result = list(self.container.query_items(
                query=total_query,
                enable_cross_partition_query=True
            ))
            total_projects = total_result[0] if total_result else 0
            
            # Count by status
            status_query = "SELECT c.status, COUNT(1) as count FROM c GROUP BY c.status"
            status_results = list(self.container.query_items(
                query=status_query,
                enable_cross_partition_query=True
            ))
            
            # Count by priority
            priority_query = "SELECT c.priority, COUNT(1) as count FROM c GROUP BY c.priority"
            priority_results = list(self.container.query_items(
                query=priority_query,
                enable_cross_partition_query=True
            ))
            
            # Count by team
            team_query = "SELECT c.team, COUNT(1) as count FROM c GROUP BY c.team"
            team_results = list(self.container.query_items(
                query=team_query,
                enable_cross_partition_query=True
            ))
            
            return {
                "total_projects": total_projects,
                "status_distribution": {r["status"]: r["count"] for r in status_results},
                "priority_distribution": {r["priority"]: r["count"] for r in priority_results},
                "team_distribution": {r["team"]: r["count"] for r in team_results},
                "last_updated": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error getting project stats: {e}")
            return {
                "total_projects": 0,
                "status_distribution": {},
                "priority_distribution": {},
                "team_distribution": {},
                "last_updated": datetime.utcnow().isoformat()
            }
```

### app/services/azure_storage.py
```python
"""
Azure Storage Service for DevOps PoC
Implements blob storage operations for API result persistence
"""
from typing import Any, Optional
import json
import logging
from datetime import datetime
from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient
from azure.core.exceptions import ResourceNotFoundError

from config.settings import get_settings

logger = logging.getLogger(__name__)


class AzureStorageService:
    """Real Azure Storage service implementation"""
    
    def __init__(self):
        """Initialize Azure Storage client"""
        settings = get_settings()
        
        self.blob_service_client = BlobServiceClient.from_connection_string(
            settings.STORAGE_CONNECTION_STRING
        )
        
        self.container_name = settings.STORAGE_CONTAINER_NAME
        self.account_name = settings.STORAGE_ACCOUNT_NAME
        
        # Get container reference
        self.container_client = self.blob_service_client.get_container_client(self.container_name)
        
        logger.info(f"Azure Storage service initialized for container: {self.container_name}")
    
    async def test_connection(self) -> bool:
        """Test Azure Storage connectivity"""
        try:
            # Try to get container properties
            properties = self.container_client.get_container_properties()
            logger.info(f"✅ Azure Storage connection successful. Container: {properties.name}")
            return True
        except ResourceNotFoundError:
            # Container doesn't exist, try to create it
            try:
                self.container_client.create_container()
                logger.info(f"✅ Created container: {self.container_name}")
                return True
            except Exception as e:
                logger.error(f"❌ Failed to create container: {e}")
                return False
        except Exception as e:
            logger.error(f"❌ Azure Storage connection failed: {e}")
            return False
    
    async def upload_text(
        self, 
        container_name: str, 
        blob_name: str, 
        data: str
    ) -> dict:
        """Upload text data to blob storage"""
        try:
            # Get blob client
            blob_client = self.blob_service_client.get_blob_client(
                container=container_name,
                blob=blob_name
            )
            
            # Upload the data
            blob_client.upload_blob(data, overwrite=True)
            
            # Get blob properties
            properties = blob_client.get_blob_properties()
            
            result = {
                "container": container_name,
                "blob": blob_name,
                "length": len(data),
                "etag": properties.etag,
                "last_modified": properties.last_modified.isoformat(),
                "url": blob_client.url
            }
            
            logger.info(f"Uploaded blob: {blob_name} ({len(data)} bytes)")
            return result
            
        except Exception as e:
            logger.error(f"Error uploading blob {blob_name}: {e}")
            raise
    
    async def upload_json(
        self, 
        container_name: str, 
        blob_name: str, 
        data: dict
    ) -> dict:
        """Upload JSON data to blob storage"""
        json_string = json.dumps(data, indent=2, default=str)
        return await self.upload_text(container_name, blob_name, json_string)
    
    async def download_text(self, container_name: str, blob_name: str) -> Optional[str]:
        """Download text data from blob storage"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=container_name,
                blob=blob_name
            )
            
            # Download the blob
            download_stream = blob_client.download_blob()
            content = download_stream.readall().decode('utf-8')
            
            logger.info(f"Downloaded blob: {blob_name}")
            return content
            
        except ResourceNotFoundError:
            logger.info(f"Blob not found: {blob_name}")
            return None
        except Exception as e:
            logger.error(f"Error downloading blob {blob_name}: {e}")
            return None
    
    async def download_json(self, container_name: str, blob_name: str) -> Optional[dict]:
        """Download JSON data from blob storage"""
        content = await self.download_text(container_name, blob_name)
        if content:
            try:
                return json.loads(content)
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing JSON from blob {blob_name}: {e}")
                return None
        return None
    
    async def list_blobs(
        self, 
        container_name: str, 
        name_starts_with: Optional[str] = None
    ) -> list:
        """List blobs in a container"""
        try:
            container_client = self.blob_service_client.get_container_client(container_name)
            
            blobs = []
            for blob in container_client.list_blobs(name_starts_with=name_starts_with):
                blobs.append({
                    "name": blob.name,
                    "size": blob.size,
                    "last_modified": blob.last_modified.isoformat(),
                    "etag": blob.etag
                })
            
            logger.info(f"Listed {len(blobs)} blobs in container: {container_name}")
            return blobs
            
        except Exception as e:
            logger.error(f"Error listing blobs in container {container_name}: {e}")
            return []
    
    async def delete_blob(self, container_name: str, blob_name: str) -> bool:
        """Delete a blob from storage"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=container_name,
                blob=blob_name
            )
            
            blob_client.delete_blob()
            
            logger.info(f"Deleted blob: {blob_name}")
            return True
            
        except ResourceNotFoundError:
            logger.info(f"Blob not found for deletion: {blob_name}")
            return False
        except Exception as e:
            logger.error(f"Error deleting blob {blob_name}: {e}")
            return False
    
    async def get_blob_properties(self, container_name: str, blob_name: str) -> Optional[dict]:
        """Get blob properties"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=container_name,
                blob=blob_name
            )
            
            properties = blob_client.get_blob_properties()
            
            return {
                "name": properties.name,
                "size": properties.size,
                "last_modified": properties.last_modified.isoformat(),
                "etag": properties.etag,
                "content_type": properties.content_settings.content_type,
                "url": blob_client.url
            }
            
        except ResourceNotFoundError:
            logger.info(f"Blob not found: {blob_name}")
            return None
        except Exception as e:
            logger.error(f"Error getting blob properties for {blob_name}: {e}")
            return None
    
    async def store_api_result(
        self, 
        operation: str, 
        data: dict, 
        prefix: str = "api-results"
    ) -> dict:
        """Store API operation result in blob storage"""
        try:
            # Generate blob name with timestamp
            timestamp = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
            blob_name = f"{prefix}/{operation}-{timestamp}.json"
            
            # Add metadata
            result_data = {
                "operation": operation,
                "timestamp": datetime.utcnow().isoformat(),
                "data": data
            }
            
            # Upload to blob storage
            result = await self.upload_json(self.container_name, blob_name, result_data)
            
            logger.info(f"Stored API result: {operation} -> {blob_name}")
            return result
            
        except Exception as e:
            logger.error(f"Error storing API result for {operation}: {e}")
            raise
```

### app/resolvers/project_resolvers.py
```python
"""
Project GraphQL resolvers for DevOps PoC
Implements CRUD operations, filtering, and pagination
"""
from typing import List, Optional
from datetime import datetime
import uuid
from strawberry import field
from strawberry.types import Info

from app.models.project import (
    Project, ProjectStats, ProjectCreateInput, ProjectUpdateInput, 
    ProjectFilterInput, ProjectPaginationInput
)
from app.services.cosmos_db import CosmosDBService
from app.services.azure_storage import AzureStorageService


class ProjectQuery:
    """Query resolvers for projects"""
    
    @field(description="Get a single project by ID")
    async def project(self, info: Info, id: str) -> Optional[Project]:
        """Retrieve a project by its ID"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        project_data = await cosmos_service.get_project(id)
        if project_data:
            return Project(**project_data)
        return None
    
    @field(description="List projects with filtering and pagination")
    async def projects(
        self, 
        info: Info,
        filter: Optional[ProjectFilterInput] = None,
        pagination: Optional[ProjectPaginationInput] = None
    ) -> List[Project]:
        """List projects with optional filtering and pagination"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        
        # Apply filters
        filter_params = {}
        if filter:
            if filter.status:
                filter_params["status"] = filter.status
            if filter.owner:
                filter_params["owner"] = filter.owner
            if filter.team:
                filter_params["team"] = filter.team
            if filter.priority:
                filter_params["priority"] = filter.priority
            if filter.risk_level:
                filter_params["risk_level"] = filter.risk_level
            if filter.tags:
                filter_params["tags"] = filter.tags
            if filter.created_after:
                filter_params["created_after"] = filter.created_after
            if filter.created_before:
                filter_params["created_before"] = filter.created_before
        
        # Apply pagination
        pagination_params = {}
        if pagination:
            pagination_params["limit"] = pagination.limit
            pagination_params["offset"] = pagination.offset
            pagination_params["sort_by"] = pagination.sort_by
            pagination_params["sort_order"] = pagination.sort_order
        
        projects_data = await cosmos_service.list_projects(
            filter_params=filter_params,
            pagination_params=pagination_params
        )
        
        return [Project(**project_data) for project_data in projects_data]
    
    @field(description="Get project statistics")
    async def project_stats(self, info: Info) -> ProjectStats:
        """Get aggregated project statistics"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        
        # Get all projects for statistics
        all_projects = await cosmos_service.list_projects()
        
        total_projects = len(all_projects)
        status_counts = {}
        priority_counts = {}
        team_counts = {}
        
        for project in all_projects:
            # Count by status
            status = project.get("status", "UNKNOWN")
            status_counts[status] = status_counts.get(status, 0) + 1
            
            # Count by priority
            priority = project.get("priority", "UNKNOWN")
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
            
            # Count by team
            team = project.get("team", "UNKNOWN")
            team_counts[team] = team_counts.get(team, 0) + 1
        
        return ProjectStats(
            total_projects=total_projects,
            status_distribution=str(status_counts),
            priority_distribution=str(priority_counts),
            team_distribution=str(team_counts),
            last_updated=datetime.utcnow().isoformat()
        )


class ProjectMutation:
    """Mutation resolvers for projects"""
    
    @field(description="Create a new project")
    async def create_project(
        self, 
        info: Info, 
        input: ProjectCreateInput
    ) -> Project:
        """Create a new project"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        storage_service: AzureStorageService = info.context["storage_service"]
        
        # Generate project ID
        project_id = str(uuid.uuid4())
        now = datetime.utcnow()
        
        # Create project document
        project_data = {
            "id": project_id,
            "name": input.name,
            "description": input.description,
            "status": input.status,
            "owner": input.owner,
            "team": input.team,
            "created_at": now,
            "updated_at": now,
            "tags": input.tags,
            "priority": input.priority,
            "estimated_completion": input.estimated_completion,
            "budget": input.budget,
            "risk_level": input.risk_level,
            "dependencies": input.dependencies
        }
        
        # Save to Cosmos DB
        created_project = await cosmos_service.create_project(project_data)
        
        # Store API result in Azure Blob Storage
        result_data = {
            "operation": "create_project",
            "project_id": project_id,
            "timestamp": now.isoformat(),
            "user": input.owner,
            "result": "success"
        }
        
        await storage_service.upload_text(
            container_name="api-results",
            blob_name=f"project-creation-{project_id}-{now.strftime('%Y%m%d-%H%M%S')}.json",
            data=str(result_data)
        )
        
        return Project(**created_project)
    
    @field(description="Update an existing project")
    async def update_project(
        self, 
        info: Info, 
        id: str, 
        input: ProjectUpdateInput
    ) -> Optional[Project]:
        """Update an existing project"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        storage_service: AzureStorageService = info.context["storage_service"]
        
        # Get existing project
        existing_project = await cosmos_service.get_project(id)
        if not existing_project:
            return None
        
        # Prepare update data
        update_data = {}
        for field, value in input.__dict__.items():
            if value is not None:
                update_data[field] = value
        
        # Add updated timestamp
        update_data["updated_at"] = datetime.utcnow()
        
        # Update in Cosmos DB
        updated_project = await cosmos_service.update_project(id, update_data)
        
        # Store API result in Azure Blob Storage
        result_data = {
            "operation": "update_project",
            "project_id": id,
            "timestamp": datetime.utcnow().isoformat(),
            "changes": update_data,
            "result": "success"
        }
        
        await storage_service.upload_text(
            container_name="api-results",
            blob_name=f"project-update-{id}-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.json",
            data=str(result_data)
        )
        
        return Project(**updated_project)
    
    @field(description="Delete a project")
    async def delete_project(self, info: Info, id: str) -> bool:
        """Delete a project"""
        cosmos_service: CosmosDBService = info.context["cosmos_service"]
        storage_service: AzureStorageService = info.context["storage_service"]
        
        # Delete from Cosmos DB
        success = await cosmos_service.delete_project(id)
        
        if success:
            # Store API result in Azure Blob Storage
            result_data = {
                "operation": "delete_project",
                "project_id": id,
                "timestamp": datetime.utcnow().isoformat(),
                "result": "success"
            }
            
            await storage_service.upload_text(
                container_name="api-results",
                blob_name=f"project-deletion-{id}-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.json",
                data=str(result_data)
            )
        
        return success


class ProjectSubscription:
    """Subscription resolvers for real-time project updates"""
    
    @field(description="Subscribe to project updates")
    async def project_updated(self, info: Info) -> Project:
        """Subscribe to real-time project updates"""
        # This is a placeholder for real-time subscriptions
        # In a real implementation, you'd use WebSockets or Azure SignalR
        pass


# Export the resolver classes
__all__ = ["ProjectQuery", "ProjectMutation", "ProjectSubscription"]
```

### app/schema/schema.py
```python
"""
GraphQL Schema for DevOps PoC
Main schema definition with project management capabilities
"""
import strawberry
from typing import List

from app.models.project import Project
from app.resolvers.project_resolvers import ProjectQuery, ProjectMutation, ProjectSubscription


@strawberry.type
class Query(ProjectQuery):
    """Root query type"""
    @strawberry.field(description="Health check endpoint")
    def health(self) -> str:
        return "ok"
    
    @strawberry.field(description="API version information")
    def version(self) -> str:
        return "1.0.0"
    
    @strawberry.field(description="API status information")
    def status(self) -> str:
        return '{"status": "healthy", "service": "devops-poc-api", "version": "1.0.0"}'


@strawberry.type
class Mutation(ProjectMutation):
    """Root mutation type"""
    @strawberry.field(description="Placeholder mutation field")
    def placeholder_mutation(self) -> str:
        return "placeholder"


@strawberry.type
class Subscription(ProjectSubscription):
    """Root subscription type"""
    @strawberry.field(description="Placeholder subscription field")
    def placeholder_subscription(self) -> str:
        return "placeholder"


# Create the GraphQL schema
schema = strawberry.Schema(
    query=Query,
    mutation=Mutation,
    subscription=Subscription
)
```

### app/middleware/auth.py
```python
from typing import Dict


async def get_current_user() -> Dict[str, object]:
    """Stub current user dependency for PoC bootstrap.

    Replace with Azure AD JWT validation.
    """
    return {"preferred_username": "demo@example.com", "roles": ["viewer"]}
```

### main.py
```python
"""
DevOps PoC - Main FastAPI Application
Demonstrates: API Development with FastAPI + GraphQL
"""
from fastapi import FastAPI, Depends, HTTPException, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from strawberry.fastapi import GraphQLRouter
from contextlib import asynccontextmanager
import uvicorn
import logging
from datetime import datetime
import uuid

from config.settings import get_settings
from app.schema.schema import schema
from app.middleware.auth import get_current_user
from app.services.azure_storage import AzureStorageService
from app.services.cosmos_db import CosmosDBService

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global services
storage_service = None
cosmos_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize services on startup"""
    global storage_service, cosmos_service
    
    settings = get_settings()
    logger.info("Initializing Azure services...")
    
    try:
        # Initialize Azure services (PoC Requirement)
        storage_service = AzureStorageService()
        cosmos_service = CosmosDBService()
        
        # Test connections
        await storage_service.test_connection()
        await cosmos_service.test_connection()
        
        logger.info("✅ Azure services initialized successfully")
        yield
        
    except Exception as e:
        logger.error(f"❌ Failed to initialize services: {e}")
        yield
    finally:
        logger.info("Shutting down services...")

# Create FastAPI app with lifecycle
app = FastAPI(
    title="DevOps Platform PoC API",
    version="1.0.0",
    description="GraphQL API demonstrating Azure integration and automation",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GraphQL Router (PoC Requirement: GraphQL APIs)
graphql_app = GraphQLRouter(
    schema,
    context_getter=lambda: {
        "storage_service": storage_service,
        "cosmos_service": cosmos_service
    }
)
app.include_router(graphql_app, prefix="/graphql")

# Health check endpoint (PoC Requirement: Monitoring)
@app.get("/health")
async def health_check():
    """Health check endpoint for container monitoring"""
    try:
        # Test Azure services connectivity
        if storage_service:
            await storage_service.test_connection()
        if cosmos_service:
            await cosmos_service.test_connection()
            
        return {
            "status": "healthy",
            "service": "devops-poc-api",
            "azure_services": "connected"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Service unhealthy")

# API Info endpoint
@app.get("/")
async def root():
    return {
        "message": "DevOps Platform PoC API",
        "graphql_endpoint": "/graphql",
        "documentation": "/docs",
        "health": "/health"
    }

# Protected endpoint example (PoC Requirement: Authentication)
@app.get("/protected")
async def protected_endpoint(current_user: dict = Depends(get_current_user)):
    """Example of protected endpoint with Azure AD authentication"""
    return {
        "message": "This is a protected endpoint",
        "user": current_user.get("preferred_username", "Unknown"),
        "roles": current_user.get("roles", [])
    }

# File upload endpoint (PoC Requirement: File Management)
@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """Upload file to Azure Blob Storage"""
    try:
        if storage_service:
            # Generate unique filename
            timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
            filename = f"{timestamp}-{file.filename}"
            
            # Read file content
            content = await file.read()
            
            # Upload to Azure Storage
            result = await storage_service.upload_text(
                container_name="api-results",
                blob_name=filename,
                data=content.decode('utf-8') if file.content_type and 'text' in file.content_type else str(content)
            )
            
            return {
                "message": "File uploaded successfully",
                "filename": filename,
                "storage_url": result["url"],
                "size": result["length"]
            }
        else:
            raise HTTPException(status_code=500, detail="Storage service not available")
    except Exception as e:
        logger.error(f"File upload failed: {e}")
        raise HTTPException(status_code=500, detail=f"File upload failed: {str(e)}")

if __name__ == "__main__":
    settings = get_settings()
    uvicorn.run(
        "main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=settings.DEBUG,
        log_level=settings.LOG_LEVEL.lower()
    )
```

## 4) Environment (.env)
```env
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true
LOG_LEVEL=INFO

AZURE_TENANT_ID=<tenant>
AZURE_CLIENT_ID=<appId>
AZURE_CLIENT_SECRET=<secret>
AZURE_SUBSCRIPTION_ID=<subscription>
AZURE_AD_AUTHORITY=https://login.microsoftonline.com/<tenant>
AZURE_AD_AUDIENCE=<appId>

COSMOS_DB_URI=https://devopspoc-cosmos-23089.documents.azure.com:443/
COSMOS_DB_KEY=<primary_key>
COSMOS_DB_DATABASE=devops-poc
COSMOS_DB_CONTAINER=projects

STORAGE_ACCOUNT_NAME=devopspocstg2025
STORAGE_CONNECTION_STRING=<connection_string>
STORAGE_CONTAINER_NAME=api-results
```

## 5) Install and Run
```bash
# Install deps
python3 -m pip install -r requirements.txt

# Verify config
python3 -c "from config.settings import get_settings; s=get_settings(); print('OK', s.API_HOST, s.API_PORT)"

# Start API (WSL/Linux)
./.venv/bin/uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# Health
curl -s http://localhost:8000/health
# GraphQL UI: open http://localhost:8000/graphql
```

## 6) Azure CLI (reference)
```bash
az login
az account set --subscription <subscription-id>
# Cosmos DB account/db/container and Storage account creation as per docs/001.md
```

This file contains everything needed to recreate the project from scratch and run it locally on WSL/Linux.
